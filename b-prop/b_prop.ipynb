{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python\n", "# coding: utf-8"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<img src=\"imagenes/rn3.png\" width=\"200\"><br>\n", "<img src=\"http://www.identidadbuho.uson.mx/assets/letragrama-rgb-150.jpg\" width=\"200\">"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# [Curso de Redes Neuronales](https://curso-redes-neuronales-unison.github.io/Temario/)<br>\n", "<br>\n", "# Redes neuronales multicapa y el algoritmo de *b-prop*<br>\n", "<br>\n", "[**Julio Waissman Vilanova**](http://mat.uson.mx/~juliowaissman/), 22 de febrero de 2018.<br>\n", "<br>\n", "En esta libreta vamos a practicar con el algoritmo b\u00e1sico para realizar reconocimiento en redes neuronales hacia adelante y establecer una estructura b\u00e1sica para simular cn fines de comprensi\u00f3n. Para aplicaciones reales vamos a utilizar herramientas poderosas como [Tensorflow](https://www.tensorflow.org), pero es importante hacer una primer red neuronal simple a pie con el objetivo de entender mejor los mecanismos b\u00e1sicos.<br>\n", "<br>\n", "Como dijo Jack el destripador, vamos por partes, y empecemos con asumir que tenemos la especificaci\u00f3n completa de la red neuronal y lo que queremos es poder generar una red neuronal inicial, o poder recuperar una red existente previamente guardada.<br>\n", "<br>\n", "Empecemos por inicializar los modulos que vamos a requerir."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import _pickle as cPickle"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Especificando una red neuronal<br>\n", "<br>\n", "Primero, para poder hacer una red neuronal, tenemos que determinar cierta informaci\u00f3n. La informaci\u00f3n importante que debemos de especificar cuando hacemos una redes neuronales es:<br>\n", "<br>\n", "- Cuantas capas de neuronas tiene la red neuronal, $L$.<br>\n", "- Cuantas neuronas va a tener cada capa $[n_0, n_1, \\ldots, n_L]$, donde $n_0$ es el n\u00famero de entradas y $n_L$ el n\u00famero de salidas.<br>\n", "- Cual es la funci\u00f3n de activaci\u00f3n de las neuronas ocultas (log\u00edstica, lineal rectificada, ...).<br>\n", "- Cual es el tipo de salida de mi red neuronal (lineal, log\u00edstica, unidad softmax, ... ).<br>\n", "- Los valores con los que se normalizan los datos de entrada a la red neuronal (para el aprendizaje en una red neuronal es muy importante que los valores de entrada est\u00e9n normalizados).<br>\n", "<br>\n", "Una vez que se establecen estos valores, es necesario generar una lista de matrices $[W^{(1)}, \\ldots, W^{(L)}]$ donde $W^{(l)}$ es una matriz de dimensiones $(n_l, n_{l-1})$ de pesos. Igualmente es necesario generar una lista de vectores $[b^{(1)}, \\ldots, b^{(L)}]$ donde $b^{(l)}$ es un vector de $n_l$ elementos llamados sesgos.<br>\n", "<br>\n", "Si se inicializan los valores de las entradas de $W^{(l)}$ y $b^{(l)}$ iguales, es equivalente a tener una sola neurona en esa capa, por lo que es necesario que estos valores sean diferentes. Para este ejemplo y con el fin de simplificar las operaciones de aprendizaje m\u00e1s adelante, vamos a asumir que la funci\u00f3n de activaci\u00f3n siempre ser\u00e1 la funci\u00f3n log\u00edstica.<br>\n", "<br>\n", "Para efectos de un mejor aprendizaje, y asumiendo que la funci\u00f3n de activaci\u00f3n es la logistica, es importante que los valores iniciales de los pesos se encuentren en la zona donde casuan m\u00e1s variacion la funci\u00f3n log\u00edstica. Si asumimos que las entradas a cada neurona est\u00e1n normalizadas (esto es, entre 0 y 1), entonces los pesos deber\u00edan ser valores entre $(-\\sqrt{n_{l-1}}, \\sqrt{n_{l-1}})$ con el fin que la suma se encuentre en la regi\u00f3n donde m\u00e1s cambios ocurren en la funci\u00f3n log\u00edstica. <br>\n", "<br>\n", "Vamos a generar y guardar esta informaci\u00f3n en un diccionario (junto con el resto de la informaci\u00f3n que requeriramos para tener una red neuronal completamente definida. Al principio los valores de normalizaci\u00f3n no cuentan ya que estos se deben inicializar al comienzo del aprendizaje. Fijate bien que naturalmente la red neuronal se deber\u00eda programar como una clase, pero para evitar complejidad que no podamos mantener en TensoFlow vamos a dejarlo todo el c\u00f3digo en forma estructurada (solo para dejar constancia).<br>\n", "<br>\n", "**Completa el c\u00f3digo para inicializar la red neuronal**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def inicializa_red_neuronal(capas, tipo):\n", "    \"\"\"\n", "    Inicializa una red neuronal como un diccionario de datos. \n", "    Se asume en este caso que la funci\u00f3n de activaci\u00f3n es la funci\u00f3n log\u00edstica\n", "    \n", "    Par\u00e1metros\n", "    ----------\n", "    neuronas_por_capa: Una lista de enteros donde el primer elemento es el n\u00famero de entradas\n", "                       y el \u00faltimo el n\u00famero de salidas, mientras que los intermedios son\n", "                       el n\u00famerode neuronas en cada capa oculta.\n", "    tipo: Un string entre {'lineal', 'logistica', 'softmax'} con el tipo de funci\u00f3n de salida de la red.\n", "    \n", "    Devuelve\n", "    --------\n", "    Un diccionario `rn` tal que\n", "        - rn['capas'] = [n0, n1, ..., nL] neuronas por capa\n", "        - rn['tipo'] = tipo\n", "        - rn['W'] = [None, W1, ..., WL] lista de matrices de pesos\n", "        - rn['b'] = [None, b1, ..., bL] lista de sesgos\n", "        - rn['mu'] = lista de medias de cada atributo (se inicializan con puros 0)\n", "        - rn['std'] = lista de desviaciones estandard de cada atributo (se inicializan con puros 1)\n", "             \n", "    \"\"\"\n", "    rn = {'capas': len(capas), 'tipo': tipo}\n", "    rn['mu'] = np.zeros(capas[0])\n", "    rn['std'] = np.ones(capas[0])    \n", "    rn['W'], rn['b'] = inicializa_Wb(capas)\n", "    return rn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def inicializa_Wb(capas):\n", "    \"\"\"\n", "    Inicializa una matriz de valores aleatorios W\n", "    \n", "    Par\u00e1metros\n", "    ----------\n", "    capas: [n0, n1, ..., nL] n\u00famero de neuronas por capa\n", "    \n", "    Devuelve\n", "    --------\n", "    W, b donde W = [None, W1, ..., WL] y b = [None, b1, ..., bL]              \n", "    \n", "    \"\"\"\n", "    #------------------------------------------------------------------------\n", "    # Agregua aqui tu c\u00f3digo\n", "    W = [None] + [np.random.rand(capas[l],capas[l-1]) for l in range(1,len(capas))]\n", "    b = [None] + [np.random.rand(capas[l]) for l in range(1,len(capas))]\n", "    \n", "    \n", "    #-------------------------------------------------------------------------\n", "    return W, b"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def test_inicializaWb():\n", "    #Vamos a hacer 1000 pruebas aleatorias que nos aseguremos que se cumpleen con las especificaciones\n", "    for _ in range(1000):\n", "        n = [np.random.randint(1, 20) for _ in range(5)]\n", "        W, b = inicializa_Wb(n)\n", "        assert len(W) == len(b) == len(n)\n", "        for l in range(1, 5):\n", "            assert W[l].shape == (n[l], n[l - 1])    # Las dimensiones son correctas\n", "            assert W[l].max() < np.sqrt(n[l - 1])    # La cota m\u00e1xima se respeta\n", "            assert W[l].min() > -np.sqrt(n[l - 1])   # La cota m\u00ednima se respeta\n", "            assert np.abs(W[l]).sum() > 0            # No estamos inicializando a 0\n", "    return \"Paso la prueba\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(test_inicializaWb())\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Como entrenar una red es algo lento y tedioso, y normalmente cuando hacemos un m\u00e9todo de aprendizaje, lo que queremos es poder utilizarlo despu\u00e9s para predecir un conjunto de datos no etiquetados previamente, es normal que guardemos en un archivo la informaci\u00f3n espec\u00edfica a la red neuronal, y despues la recuperemos en otra sesi\u00f3n, otro d\u00eda, o en otra computadora para hacer la predicci\u00f3n.<br>\n", "<br>\n", "Una manera de guardar datos, funciones y objectos de Python en disco es utilizando el m\u00f3dulo ``pickle`` (o su versi\u00f3n compilada para mayor velocidad ``cPickle``). Este modulo permite guardar una serie de objetos de python en forma serializada en un archivo binario, y luego recuperarlos. Notese que este m\u00e9todo es diferente a ``np.load`` y ``np.savez``, ya que estos solo permiten guardar (y recuperar) una serie de ndarrays \u00fanicamente. <br>\n", "<br>\n", "Vamos entonces a hacer dos funciones muy simples ``guarda_objeto`` y ``carga_objeto``, que utilizaremos m\u00e1s adelante."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def guarda_objeto(archivo, objeto):\n", "    \"\"\"\n", "    Guarda un objeto de python en el archivo \"archivo\". Si el archivo existe, sera reemplazado sin \n", "    preguntas, al puro estilo mafioso.\n", "    \n", "    Par\u00e1metros\n", "    ----------\n", "    archivo: string con el nombre de un archivo (aunque no exista)\n", "    objeto: Un objeto de python para ser guardado\n", "    \n", "    \"\"\"\n", "    \n", "    with open(archivo, 'wb') as arch:\n", "        cPickle.dump(objeto, arch, -1)\n", "        arch.close()\n", "        \n", "def carga_objeto(archivo):\n", "    \"\"\"\n", "    Carga el primer (y se asume que \u00fanico) objeto contenido en el archivo 'archivo' que debe de ser tipo cPickle.\n", "    \n", "    Par\u00e1metros\n", "    ----------\n", "    archivo: string con el nombre de un archivo tipo pickle\n", "    \n", "    Devuelve\n", "    --------\n", "    El primer objeto dentro del picke\n", "    \n", "    \"\"\"\n", "    with open(archivo, 'rb') as arch:\n", "        objeto = cPickle.load(arch)\n", "        arch.close()\n", "        return objeto\n", "    \n", "def test_archivo():\n", "    \"\"\"\n", "    Prueba, para esto vamos a cargar o a leer (o ambas cosas) un objeto en un archivo\n", "    \n", "    Por favor, borrar el archivo cada vez que se pruebe, o para probar la lectura y la escritura\n", "    \n", "    \"\"\"\n", "    temp = [range(100), 'prueba', True]\n", "    guarda_objeto('prueba.pkl', temp)\n", "    temp =[10, 'no prueba', False]\n", "    otro = carga_objeto('prueba.pkl')\n", "    assert len(otro[0]) == 100\n", "    assert otro[1] == 'prueba'\n", "    assert otro[-1]\n", "    \n", "    return \"Pasa la prueba\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(test_archivo())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Calculando la salida de una red neuronal con *feedforward*<br>\n", "<br>\n", "<br>\n", "Asumamos que tenemos una red neuronal ya inicializada, y que la vamos a utilizar para calcular el costo de una soluci\u00f3n. Como vimos en clase, el costo de la soluci\u00f3n depende del tipo de neuronas de salida (que son en realidad la etapa de clasificaci\u00f3n). As\u00ed, para calcular el costo, es necesario calcular la salida de la red neuronal.<br>\n", "<br>\n", "Recordemos que el algoritmo para realizar la alimentaci\u00f3n hacia adelante de una red neuronal el algoritmo es el siguiente:<br>\n", "<br>\n", "1. Normaliza los valores de entrada $X_{norm}$<br>\n", "<br>\n", "1. Inicializa $a^{(0)} \\leftarrow X_{norm}^T$<br>\n", "<br>\n", "2. Por cada capa $l$ de 1 a $L-1$:<br>\n", "<br>\n", "    1. Se calcula el valor de $z^{(l)} \\leftarrow W^{(l)} a^{(l-1)} + b^{(l)}$ <br>\n", "       <br>\n", "    2. Se calcula $a^{(l)} \\leftarrow g(z^{(l)})$ donde $g$ es la funci\u00f3n de activaci\u00f3n (en nuestro caso hemos <br>\n", "       decidido utilizar la funci\u00f3n log\u00edstica, pero podr\u00edamos tener otras funciones de activaci\u00f3n).<br>\n", "<br>\n", "3. Se calcula $z^{(L)} \\leftarrow W^{(L)} a^{(L-1)} + b^{(L)}$ <br>\n", "<br>\n", "4. Se calcula $a^{(L)}$ de acuerdo a la funci\u00f3n de activaci\u00f3n dependiendo del tipo de salida:<br>\n", "<br>\n", "    * Si `tipo = 'logistica'` entonces $a^{(L)} = logistica(z^{(L)})$.<br>\n", "    * Si `tipo = 'lineal'` entonces $a^{(L)} = z^{(L)}$.<br>\n", "    * Si `tipo = 'softmax'` entonces $a^{(L)} = softmax(z^{(L)}).$<br>\n", "<br>\n", "5. La salida de la red es $(a^{(L)})^T$.<br>\n", "<br>\n", "<br>\n", "**Completa el c\u00f3digo de las funciones necesarias para normalizar las entradas y calcular las salidas y la activaci\u00f3n de la red *feedforward*. En particular toma en cuanta que en este caso la funci\u00f3n de softmax se realiza sobre las columnas y no sobre los renglones (como en la libreta de softmax).**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def mu_std(x):\n", "    \"\"\"\n", "    Obtiene las medias y las desviaciones estandar atributo a atributo.\n", "    \n", "    Par\u00e1metros\n", "    ----------\n", "    x: un ndarray de shape (M, n) con los datos\n", "    Devuelve\n", "    ---------\n", "    mu, de ndarrays de shape (n,) con las medias y las desviaciones estandar respectivamente.\n", "    \n", "    \"\"\"\n", "    return x.mean(axis=0), x.std(axis=0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def normaliza(x, mu, de):\n", "    \"\"\"\n", "    Normaliza los datos x\n", "    Par\u00e1metros\n", "    ----------\n", "    x: un ndarray de shape (M, n) con los datos\n", "    mu: ndarray de shape (n,) con las medias \n", "    de: ndarray de shape (n,) con las desviaciones estandar\n", "    \n", "    Devuelve\n", "    --------\n", "    x_norm un ndarray de las mismas dimensiones de x pero normalizado\n", "    \n", "    \"\"\"\n", "    return (x - mu.reshape(1,-1)) / de.reshape(1,-1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def logistica(z):\n", "    \"\"\"\n", "    Calcula la funci\u00f3n log\u00edstica para cada elemento de z\n", "    \n", "    Par\u00e1metros\n", "    ----------\n", "    z: un ndarray\n", "    \n", "    Devuelve\n", "    ---------\n", "    Un ndarray de las mismas dimensiones que z\n", "    \n", "    \"\"\"\n", "    # --- Agrega aqui tu c\u00f3digo ---\n", "    return 1/(1 + np.exp(-z))\n", "    \n", "    \n", "    # -----------------------------\n", "    \n", "def softmax(z):\n", "    \"\"\"\n", "    Calculo de la regresi\u00f3n softmax\n", "    \n", "    Par\u00e1metros\n", "    ----------\n", "    z: ndarray de dimensi\u00f3n (K, M) donde z[:, i] es el vector de aportes lineales \n", "       a cada clase del objeto o situaci\u00f3n i-\u00e9sima\n", "    Devuelve\n", "    --------\n", "    Un ndarray de dimensi\u00f3n (K, M) donde cada columna es el calculo softmax \n", "    de su respectivo vector de entrada.\n", "    \n", "    \"\"\"\n", "    # --- Agrega aqui tu c\u00f3digo ---\n", "    temp = z - np.max(z, axis=0)\n", "    t = np.exp(temp)\n", "    return t / np.sum(t, axis=0)\n", "    \n", "    \n", "    # -----------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def prueba_salidas():\n", "    \n", "    # Para la log\u00edstica\n", "    z = np.array([-10, 0, 10, 0.5])\n", "    a = logistica(z)\n", "    assert 0 < a[0] < 0.01\n", "    assert 0.49 < a[1] < 0.51\n", "    assert 1 > a[2] > 0.99\n", "    assert 0.621 < a[3] < 0.623\n", "    \n", "    # Para softmax\n", "    z = np.random.rand(4, 20)\n", "    a = softmax(z)\n", "    cum = a.sum(axis=0)\n", "    assert z.shape == a.shape\n", "    assert cum.shape == (20, )\n", "    assert np.all(cum > 0.999)\n", "    assert np.all(cum < 1.001)\n", "    \n", "    z = np.array([[2,      1, -1000],\n", "                  [2,    -30,   -10],\n", "                  [2, -10000, 20000]])\n", "    a = softmax(z)\n", "    assert a[0, 0] == a[1, 0] == a[2, 0]\n", "    assert a[0, 1] > 0.99\n", "    assert a[0, 1] + a[1, 1] + a[2, 1] < 1.001\n", "    assert a[2, 2] > 0.99\n", "    assert a[0, 2] + a[1, 2] + a[2, 2] < 1.001\n", "    \n", "    return \"Paso la prueba\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(prueba_salidas())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Y ahora hay que programar el m\u00e9todo de alimentaci\u00f3n hacia adelante**."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def f_prop(X, red_neuronal):\n", "    \"\"\"\n", "    Calcula las activaciones en todas las capas para los valores de `X` utilizando red_neuronal.\n", "    \n", "    A partir de aqui se puede obtener la salida como A[-1].T (las activaciones de la \u00faltima capa, transpuestas)\n", "    \n", "    Par\u00e1metros\n", "    ----------\n", "    X: ndarray de shape (M, n) donde T es el n\u00famero de ejemplos y n el n\u00famero de atributos\n", "    red_neuronal: Estructura de datos de una red neuronal inicializada con la funci\u00f3n `inicializa_red_neuronal``\n", "    \n", "    Devuelve\n", "    --------\n", "    A = [A0, A1, ..., AL] una lista de activaciones por capa, donde A[l] es una matriz de\n", "        activaciones con forma (nl, M) donde nl es el n\u00famero de neuronas de la capa l.\n", "             \n", "    \"\"\"    \n", "    # Inicializar A = [A0], donde A0 son las activaciones de la capa de entrada\n", "    # ----------Agregar c\u00f3digo aqui -----------------    \n", "    A0 = X.T\n", "    \n", "    #-------------------------------------------------\n", "    A = [A0]\n", "    \n", "    # Despues vamos a hacer lo propio por cada capa hasta antes de la \u00faltima\n", "    for (Wl, bl) in zip(red_neuronal['W'][1:-1], red_neuronal['b'][1:-1]):         \n", "        # ----------Agregar c\u00f3digo aqui -----------------\n", "        z = ((Wl @ A[-1]).T + bl).T\n", "        \n", "        Al = logistica(z)\n", "        \n", "        #-------------------------------------------------\n", "        A.append(Al)\n", "        \n", "    # Calcula A^{L} y agrega a A de acuerdo al tipo de salida\n", "    # ----------Agregar c\u00f3digo aqui -------------------------------\n", "    z = ((red_neuronal[\"W\"][-1] @ A[-1]).T + red_neuronal[\"b\"][-1]).T\n", "    \n", "    if red_neuronal[\"tipo\"] is \"logistica\":\n", "        Al = logistica(z)\n", "    elif red_neuronal[\"tipo\"] is \"softmax\":\n", "        Al = softmax(z)\n", "    else:\n", "        Al = z # <--- De acuerdo al tipo de salida\n", "    \n", "    #-------------------------------------------------        \n", "    A.append(Al)\n", "    return A\n", "                                      \n", "    \n", "    \n", "def prueba_feedforward():\n", "    \"\"\"\n", "    Funci\u00f3n para validar la funci\u00f3n de fedforward \n", "    \n", "    Se inicializa una red de dos capas (m\u00e1s capa de entrada) y se \n", "    imponen los pesos. Esto se hizo a mano para las diferentes\n", "    entradas, as\u00ed que se espera que la funci\u00f3n de feedforward de\n", "    cosas similares\n", "    \"\"\"\n", "    # Inicializa red neuronal\n", "    rn = inicializa_red_neuronal([2, 2, 1], 'lineal')\n", "    \n", "    # Modificamos pesos y los sesgos\n", "    rn['W'][1] = np.array([[-0.3, -0.7],\n", "                           [0.2, 0.3]])\n", "    rn['W'][2] = np.array([[0.5, -0.5]])\n", "    \n", "    rn['b'][1] = np.array([0.5, -1])\n", "    rn['b'][2] = np.array([0])\n", "    \n", "    #Ponemos algunas entradas sencillas\n", "    x = np.array([[0,   0],\n", "                  [1,   1],\n", "                  [-1, -1]])\n", "    \n", "    # Y el valor de A calculado a mano\n", "    A1 = np.array([[0.6225, 0.3775, 0.8176],\n", "                   [0.2689, 0.3775, 0.1824]])\n", "    A2 = np.array([0.17676, 0, 0.3176])\n", "    \n", "    A = f_prop(x, rn)\n", "    assert np.sum(np.abs(A[1] - A1)) <= 0.001\n", "    assert np.sum(np.abs(A[2] - A2)) <= 0.001\n", "    \n", "    #Ahora vamos a ver que pasa si cambiamos la salida\n", "    rn['tipo'] = 'logistica'\n", "    A = f_prop(x, rn)\n", "    A2 = np.array([0.544075, 0.5, 0.5787])\n", "    assert np.sum(np.abs(A[2] - A2)) <= 0.001\n", "    \n", "    return \"Paso la prueba\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(prueba_feedforward())\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Calcula una funci\u00f3n s\u00edmple de p\u00e9rdida de una red neuronal<br>\n", "<br>\n", "Con  la funci\u00f3n de feedforward desarrollada, podemos retomar las funciones desarrolladas en las libretas anteriores para calcular la funci\u00f3n de p\u00e9rdida, dependiendo del tipo de salida.<br>\n", "<br>\n", "#### Ejercicio 3: Completa el c\u00f3digo de la funci\u00f3n de perdida de acuerdo a las 3 salidas posibles de la red neuronal."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def perdida_red(X, Y, rn):\n", "    \"\"\"\n", "    Calcula la funci\u00f3n de perdida de una red neuronal, de acuerdo al tipo de salida\n", "    y a un conjunto de datos conocidos expresados por Y y X\n", "    Par\u00e1metros\n", "    ----------\n", "    X: un ndarray de dimension (T, N) con los valores de entrada\n", "    Y: un ndarray de dimension (T, K) con los valores de salida\n", "    rn: una red neuronal\n", "    Devuelve\n", "    --------\n", "    Un flotante con el valor de la funci\u00f3n de Loss\n", "    \n", "    \"\"\"\n", "    Y_est = f_prop(X, rn)[-1].T\n", "    return Loss(Y, Y_est, rn['tipo'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def Loss(Y, Y_est, tipo):\n", "    \"\"\"\n", "    Calcula la funci\u00f3n de perdida de una red neuronal, de acuerdo al tipo de salida \n", "    Par\u00e1metros\n", "    ----------\n", "    Y: un ndarray de dimension (M, K) con los objetivos o salidas esperadas\n", "    Y_est: un ndarray de dimension (M, K) con los valores de salida de la red neuronal\n", "    tipo: Un string que puede ser 'lineal', 'logistica'o 'softmax'\n", "    Devuelve\n", "    --------\n", "    Un flotante con el valor de la funci\u00f3n de Loss\n", "    \n", "    \"\"\"\n", "    M, K = Y.shape\n", "    \n", "    # ----------Agregar c\u00f3digo aqui -------------------------------\n", "    if tipo == \"lineal\":\n", "        loss = 1/(2*M) * np.sum((Y - Y_est)**2)\n", "    if tipo == \"logistica\":\n", "        loss = -1/M * np.sum(Y*np.log(Y_est) + (1-Y)*np.log(1-Y_est))\n", "    if tipo == \"softmax\":\n", "        loss = -1/M * np.sum(Y * np.log(Y_est))    \n", "    \n", "    # -------------------------------------------------------------\n", "    return loss\n", "    \n", "    \n", "    \n", "def prueba_perdida():\n", "    \"\"\"\n", "    La unidad de prueba de la funci\u00f3n costo\n", "    \n", "    \"\"\"\n", "    Y = np.array([[.1, 2.2, 3.6, 0]]).T\n", "    Y_est = np.array([[.3, 2.0, 3.8, -0.2]]).T\n", "    assert abs(Loss(Y, Y_est, 'lineal') - 0.02) < 1e-8\n", "    \n", "    Y = np.array([[1, 0, 1, 0]]).T\n", "    Y_est = np.array([[.9, 0.1, 0.8, 0.2]]).T\n", "    assert abs(Loss(Y, Y_est, 'logistica') - 0.164252033486018) < 1e-8\n", "    \n", "    Y = np.array([[1, 0, 1, 0], \n", "                  [0, 1, 0, 0], \n", "                  [0, 0, 0, 1]]).T\n", "    Y_est = np.array([[0.8, 0.1, 0.1], \n", "                      [0.15, 0.8, 0.05],\n", "                      [0.9, 0.05, 0.05],\n", "                      [0.021, 0.079, 0.9]])\n", "    assert abs(Loss(Y, Y_est, 'softmax') - 0.164252033486018) < 1e-8\n", "    assert abs(Loss(Y, Y_est, 'lineal') - 0.01958525) < 1e-8\n", "    \n", "    return 'paso la prueba'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(prueba_perdida())\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. El algortmo de *backpropagation*<br>\n", "<br>\n", "La derivada parcial de la funci\u00f3n de p\u00e9rdida respecto a cada uno de los pesos (por lo tanto el gradiente de la funci\u00f3n de p\u00e9rdida) se obtiene mediante el algoritmo de backpropagarion. Una vez que se conoce esto, entonces es posible utilizar el resultado para entrenar la red neuronal mediente el m\u00e9todo de descenso de gradiente o una variente.<br>\n", "<br>\n", "Sea $CA = \\{(x^{(1), y^{(1)}), \\ldots, (x^{(M), y^{(M)})} el conjunto de datos de entrenamiento. El algoritmo de *backpropagation* es el siguiente:<br>\n", "<br>\n", "1. Calcular el vector $\\delta^{(L)}$ para todos los datos a partir de $A^{L}$ y $Y$, y el tipo de salida. Si utilizamos la funci\u00f3n de p\u00e9rdida correcta para cada tipo de salida, entonces esto se calcula en forma muy sencilla, tal como vimos en clases $$\\delta^{(L)} = Y^T - A^{(L)}.$$<br>\n", "<br>\n", "2. Para $l$ de $L-1$ hasta 1 con decrementos de $-1$:<br>\n", "    1. Calcular $\\delta^{(l)}$ a partir de $\\delta^{(l+1)}$, $W^{(l+1)}$ y $A^{(l)}$ como<br>\n", "       $$<br>\n", "       \\delta^{(l)} = A^{(l)} \\star (\\vec{1} - A^{(l)}) \\star ((W^{(l+1)})^T \\delta^{(l+1)}), <br>\n", "       $$<br>\n", "       donde $\\star$ es la multiplicaci\u00f3n elemento a elemento de dos matrices y $\\vec(1)$ es una matriz con 1 en todos sus elementos.<br>\n", "    2. Calcular la derivada en cada uno de los pesos como<br>\n", "       $$<br>\n", "       \\frac{\\partial Loss(W, b)}{\\partial w_{ij}^{(l)}} = \\frac{1}{M}\\sum_{\\forall (x,y) \\in CA} a_j^{(l-1)} \\delta_i^{(l)},<br>\n", "       $$<br>\n", "       y<br>\n", "       $$<br>\n", "       \\frac{\\partial Loss(W), b}{\\partial b_{i}^{(l)}} = \\frac{1}{M}\\sum_{\\forall (x,y) \\in CA} \\delta_i^{(l)},       <br>\n", "       $$<br>\n", "       <br>\n", "El desarrollo del algoritmo y los pasos en forma matricial se vieron con detalle en clase, por lo que aqui solo se da un peque\u00f1\u00f1o bosquejo esperando que se programe correctamente.<br>\n", "<br>\n", "**Completa el c\u00f3digo de la funci\u00f3n de backpropagation.**<br>\n", "<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def b_prop(Y, A, rn):\n", "    \"\"\"\n", "    Calcula el gradiente de los pesos de una red neuronal\n", "    \n", "    Parametros\n", "    -----------\n", "    Y: ndarray de shape (M, K) donde M es el n\u00famero de ejemplos y K el n\u00famero de salidas\n", "    \n", "    A: Una lista de matrices de activaciones por capas, obtenidas por la funci\u00f3n `f_prop`,\n", "       en donde A[l] es un ndarray de shape (nl, M), donde M es el n\u00famero de ejemplos evaluados \n", "       y nl es el n\u00famero de neuronas de la capa l de rn.\n", "    rn: Estructura de datos de una red neuronal inicializada con la funci\u00f3n \n", "        `inicializa_red_neuronal`\n", "    \n", "    Devuelve\n", "    --------\n", "    gW, gb, tales que: \n", "        gW = [None, gW1, ..., gWL], donde cada gWl es un ndarray tal que \n", "             rn['W'][l].shape == gWl.shape \n", "        gb = [None, gb1, ..., gbL] ta que rn['b'][l].shape == wb[l],\n", "             con las derivadas parciales calculadas para cada par\u00e1metro.\n", "             \n", "    \"\"\"    \n", "    # Numero de ejemplos\n", "    M, K = Y.shape\n", "    gW, gb = [], []\n\n", "    # Calcula delta, gW_L y gb_l para la capa de salida\n", "    delta = -(Y.T - A[-1])\n", "    gW_L = delta @ A[-2].T / M\n", "    gb_L = delta.mean(axis=1)\n", "    \n", "    # Agrega a la lista\n", "    gW.append(gW_L)\n", "    gb.append(gb_L)\n", "    \n", "    # Despu\u00e9s vamos a hacer lo propio por cada capa hasta antes de la \u00faltima\n", "    for l in range(rn['capas'] - 2, 0, -1):         \n", "        \n", "        # Calcula la delta, gW_l y gb_l para la capa anterior.        \n", "        \n", "        # ----------Agregar c\u00f3digo aqui -----------------\n", "        delta = A[l]*(1-A[l])*(rn[\"W\"][l+1].T @ delta)\n", "        gW_l = (delta @ A[l-1].T)/M\n", "        gb_l = (np.sum(delta, axis=1))/M\n", "        \n", "        # ------------------------------------------------\n", "        gW.append(gW_l)\n", "        gb.append(gb_l)\n", "    gW.reverse()\n", "    gb.reverse()\n", "    gW = [None] + gW\n", "    gb = [None] + gb        \n", "    return gW, gb"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Revisar y corregir c\u00f3digo de aprendizaje m\u00e1quina<br>\n", "<br>\n", "El problema con este tipo de algoritmos es que, a la hora de codificarlos, es muy t\u00edpico que se tengan errores, tanto de concepto como de codificaci\u00f3n. Sin embargo, como estos algortimos se utilizan para aprender, y al utilizar un conjunto inicial de pesos aleatorio diferente, los resultados no son verificables. Es muy com\u00fan tener un error muy tonto y pasar muchas horas (o d\u00edas) intentando corregirlo.<br>\n", "<br>\n", "Por esta raz\u00f3n, siempre hay que hacer m\u00e9todos que nos permitan chacar que el algortimo parece funcionar correctamente. Para eso, vamos a programar una forma alternativa de calcular una aproximaci\u00f3n del gradiente en forma num\u00e9rica. Este algortimo de fuerza bruta es altamente ineficiente y no puede ser utilizada dentro de un m\u00e9todo de optimizaci\u00f3n pero nos sirve para revisar si existen errores que podr\u00edamos haber ingresado en nuestro algoritmo.<br>\n", "<br>\n", "El m\u00e9todo se basa en el calculo num\u00e9rico de una derivada parcial como:<br>\n", "<br>\n", "$$<br>\n", "  \\left.\\frac{\\partial f(x)}{\\partial x}\\right|_{x = x_0} \\approx \\frac{f(x_0 + \\epsilon) - f(x_0 - \\epsilon)}{2 \\epsilon}.  <br>\n", "$$<br>\n", "<br>\n", "Entonces, si queremos estimar el gradiente de la funci\u00f3n de p\u00e9rdida respecto a los pesos, hay que calcular esta raz\u00f3n por cada uno de los pesos, por cada una de las capas. Esto no es nada eficiente y mucho menos elegante (como el *b-prop*) pero es un m\u00e9todo de validaci\u00f3n.<br>\n", "<br>\n", "**Completa el c\u00f3digo de la funci\u00f3n de gradiente num\u00e9rico.**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def gradiente_numerico(X, Y, rn, epsilon=1e-3):\n", "    \"\"\"\n", "    Calcula el gradiente num\u00e9rico para efectos de prueba del algoritmo de backpropagation.\n", "    Este algortimo se realiza expresamente de manera ineficiente pero clara, ya que su\n", "    funcionamiento debe de ser lo m\u00e1s claro posible.\n", "    \n", "    Par\u00e1metros\n", "    ----------\n", "    X: ndarray de shape (M, n) donde M es el n\u00famero de ejemplos y n el n\u00famero de atributos\n", "    Y: ndarray de shape (M, K) donde K es el n\u00famero de salidas\n", "    rn: Estructura de datos de una red neuronal inicializada con la funci\u00f3n `inicializa_red_neuronal``\n", "    epsilon: Un n\u00famero flotante positivo, t\u00edpicamente muy peque\u00f1o\n", " \n", "    Devuelve\n", "    --------\n", "    gW, gb, tales que: \n", "        gW = [None, gW1, ..., gWL], donde cada gWl es un ndarray tal que \n", "             rn['W'][l].shape == gWl.shape \n", "        gb = [None, gb1, ..., gbL] ta que rn['b'][l].shape == wb[l],\n", "             con las derivadas parciales calculadas para cada par\u00e1metro.\n", "    \"\"\"\n", "    # inicializa gW y gB\n", "    gW = [None] + [np.ones_like(Wl) for Wl in rn['W'][1:]]\n", "    gb = [None] + [np.ones_like(bl) for bl in rn['b'][1:]]\n", "    \n", "    for l in range(1,rn['capas']):                #  Por cada capa l\n", "        for i in range(rn['W'][l].shape[0]):          #  Por cada renglon i\n", "            for j in range(rn['W'][l].shape[1]):      #  Por cada columna j\n", "                # -------------------------------------------\n", "                # Insertar c\u00f3digo aqu\u00ed\n", "                # -------------------------------------------\n", "                rn[\"W\"][l][i][j] += epsilon\n", "                f_b = f_a = Loss(Y, f_prop(X, rn)[-1].T, rn[\"tipo\"])\n", "                \n", "                rn[\"W\"][l][i][j] -= 2*epsilon\n", "                f_a = Loss(Y, f_prop(X, rn)[-1].T, rn[\"tipo\"])\n", "                \n", "                gW[l][i][j] = (f_b - f_a)/(2*epsilon)\n", "                rn[\"W\"][l][i][j] += epsilon\n", "                            \n", "                # -------------------------------------------\n", "            # -------------------------------------------\n", "            # Insertar c\u00f3digo aqu\u00ed\n", "            # -------------------------------------------\n", "            rn[\"b\"][l][i] += epsilon\n", "            f_b = Loss(Y, f_prop(X, rn)[-1].T, rn[\"tipo\"])\n", "            \n", "            rn[\"b\"][l][i] -= 2*epsilon\n", "            f_a = Loss(Y, f_prop(X, rn)[-1].T, rn[\"tipo\"])\n", "            gb[l][i] = (f_b - f_a)/(2*epsilon)\n", "            rn[\"b\"][l][i] += epsilon \n", "            \n", "            # --------------------------------------------\n", "    return gW, gb           \n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ahora vamos a hacer una funci\u00f3n de prueba utilizando un conjunto de datos reales (o un subconjunto de estos), y lo vamos a hacer para muchas posibles reinicializaciones de pesos. Este c\u00f3digo va a servir para corregir ambos algoritmos de calculo de gradiente.  Para esto vamos a utilizar una base de datos ya conocida, la de d\u00edgitos, utilizada en la libreta de regresi\u00f3n softmax."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Datos a utilizar para la prueba<br>\n", "para no tener que estarlos cargando de nuevo cada vez"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Vamos a utilizar un subconkunto de datos y de atributos<br>\n", "para que pueda funcionar el gradiente num\u00e9rico en un tiempo <br>\n", "aceptable"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = np.load(\"datos/digitos.npz\")\n", "x_prueba = data['X_entrena'][:100,:10]  # Solo 100 datos y 10 par\u00e1metros\n", "y_prueba = data['T_entrena'][:100,:]    # Todas las clases de los primeros 100 datos"]}, {"cell_type": "markdown", "metadata": {}, "source": ["No seguir m\u00e1s all\u00e1 en la programaci\u00f3n de la red neuronal hasta estar seguro que esto funcione correctamente."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def prueba_gradiente(X, Y):\n", "    \"\"\"\n", "    Unidad de prueba de backpropagation\n", "    \n", "    \"\"\"\n", "    n0 = X.shape[1]\n", "    nL = Y.shape[1]\n", "    \n", "    for ocultas in [2, 3]: \n", "        for neuronas in [2, 3]:\n", "            rn = inicializa_red_neuronal([n0] + (ocultas * [neuronas * n0]) + [nL],\n", "                                         'lineal')\n", "            for tipo in ['logistica', 'softmax', 'lineal']:\n", "                rn['tipo'] = tipo\n", "                A = f_prop(X, rn)\n", "                gW, gb = b_prop(Y, A, rn)\n", "                gWn, gbn = gradiente_numerico(X, Y, rn, 1e-3)\n", "                \n", "                diferenciasW = [np.abs(gwl - gwln).max() \n", "                                for (gwl, gwln) in zip(gW[1:], gWn[1:])]\n", "                diferenciasb = [np.abs(bl - bln).max() \n", "                                for (bl, bln) in zip(gb[1:], gbn[1:])]\n", "                print(\"Tipo: {}, Neuronas: {}\".format(rn['tipo'], rn['capas']))\n", "                print(\"M\u00e1xima diferencia entre m\u00e9todos de gradiente para w: {}\".format(max(diferenciasW)))\n", "                print(\"M\u00e1xima diferencia entre m\u00e9todos de gradiente para b: {}\".format(max(diferenciasb)))\n", "                if max(diferenciasW) > 1e-3:\n", "                    print(gW[-1])\n", "                    print(gWn[-1])\n", "                assert max(diferenciasW) < 1e-3\n", "                assert max(diferenciasb) < 1e-3\n", "    return \"Paso la prueba\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(prueba_gradiente(x_prueba, y_prueba))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. El algoritmo de descenso de gradiente <br>\n", "<br>\n", "Ya que estamos seguros que el m\u00e9todo de *b-prop* funciona correcatamente, entonces ya podemos poner todo junto muy f\u00e1cilmente para realizar aprendizaje. Para esto vamos a utilizar el m\u00e9todo de descenso de gradiente, el cual, en su forma m\u00e1s simple por lotes no es m\u00e1s que repetir por un n\u00famero de veces (*epochs*) el calculo del gradiente y modificar los pesos de la red en direcci\u00f3n contraria a estos. <br>\n", "<br>\n", "En forma de algoritmo esto ser\u00eda realizar los siguientes pasos:<br>\n", "<br>\n", "1. De 1 a `max_epochs`:<br>\n", "    1. Calcular las activaciones `A` con el algoritmo de *feedforward*<br>\n", "    2. Calcular los gradientes $\\nabla_W^{(l)}Loss(W, b)$ y $\\nabla_b^{(l)}Loss(W, b)$ para toda capa $l$, con el algoritmo de *backpropagation*.<br>\n", "    3. Actualizar los pesos como<br>\n", "       $$<br>\n", "       W^{(l)} \\leftarrow W^{(l)} - \\alpha \\nabla_W^{(l)}Loss(W, b),\\\\ <br>\n", "       b^{(l)} \\leftarrow b^{(l)} - \\alpha \\nabla_b^{(l)}Loss(W, b).<br>\n", "       $$<br>\n", "       <br>\n", "Como vemos, en este algoritmo solo hay que especificar dos variables, la tasa de aprendizaje $\\alpha$ y el n\u00famero m\u00e1ximo de *epochs*. Este algoritmo solo lo ponemos como una primera aproximaci\u00f3n, pero es un m\u00e9todo de base del cual partiremos para realizar mejores algoritmos de aprendizaje.<br>\n", "<br>\n", "**Completa el c\u00f3digo de la funci\u00f3n de descenso de gradiente.**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def desc_grad(X, Y, rn, alfa=0.2, max_epochs=1000):\n", "    \"\"\"\n", "    Entrena una red neuronal utilizando el m\u00e9todo de descenso de gradiente simple\n", "    \n", "    Par\u00e1metros\n", "    ----------\n", "    X: ndarray de shape (M, n) donde M es el n\u00famero de ejemplos y n el n\u00famero de atributos\n", "    Y: ndarray de shape (M, K) donde K es el n\u00famero de salidas\n", "    rn: Estructura de datos de una red neuronal inicializada con la funci\u00f3n `inicializa_red_neuronal``\n", "    alfa: La tasa de aprendizaje, un n\u00famero flotante positivo\n", "    max_epochs: N\u00famero de epocas o iteraciones del algoritmo. Un entero positivo.\n", "    normaliza: Un booleano para usar X y Y para normalizar o no los datos antes de entrar a la rn.\n", "    \n", "    Devuelve\n", "    --------\n", "    None, la funci\u00f3n utiliza el hecho que rn es un objeto mutabe y modifica rn['W'] directamente.\n", "    \n", "    \"\"\"\n", "            \n", "    # Aprendizaje\n", "    for _ in range(max_epochs):\n", "        # Calcula las activaciones\n", "        # -------------------------------------------\n", "        # Insertar c\u00f3digo aqu\u00ed\n", "        # -------------------------------------------\n", "        a = f_prop(X,rn)\n", "        \n", "        # Calcula los gradientes\n", "        # -------------------------------------------\n", "        # Insertar c\u00f3digo aqu\u00ed\n", "        # -------------------------------------------\n", "        dw,db = b_prop(Y,a,rn)\n", "        \n", "        # Actualiza los pesos\n", "        # -------------------------------------------\n", "        # Insertar c\u00f3digo aqu\u00ed\n", "        # -------------------------------------------\n", "        for l in range(1, rn[\"capas\"]):\n", "            rn[\"W\"][l] -= alfa*dw[l]\n", "            rn[\"b\"][l] -= alfa*db[l]\n", "        "]}, {"cell_type": "markdown", "metadata": {}, "source": ["Y ahora hay que probar que el algoritmo funciona para un problema sencillo que nos permita encontrar problemas en su codificaci\u00f3n. Para esto vamos a generar un conjunto de datos de entrenamiento, los cuales los podremos visualizar f\u00e1cilmente."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Biblioteca de graficaci\u00f3n y configuracion de figuras"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["get_ipython().run_line_magic('matplotlib', 'inline')\n", "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n", "plt.rcParams['image.interpolation'] = 'nearest'\n", "plt.rcParams['image.cmap'] = 'gray'"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Inicializaci\u00f3n de datos"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(0) # Aseguramos que siempre pasa lo mismo\n", "N = 100 # Ejemplos por clase\n", "D = 2 # Atributos\n", "K = 3 # Clases\n", "X = np.zeros((N * K, D))\n", "Y = np.zeros((N * K, K), dtype='uint8')\n", "y = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Genera datos en espiral"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for clase in range(K):\n", "  ix = list(range(N*clase, N*(clase+1)))  # Indices para cada clase\n", "  r = np.linspace(0.0, 1, N) \n", "  t = np.linspace(clase * 4, (clase + 1) * 4, N) + np.random.randn(N) * 0.2 \n", "  X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n", "  Y[ix, clase] = 1\n", "  y.extend([['red', 'yellow', 'blue'][clase] for _ in ix])"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Grafica datos"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure()\n", "plt.scatter(X[:, 0], X[:, 1], c = y, s=40, cmap=plt.cm.Spectral)\n", "plt.xlim([-1,1])\n", "plt.ylim([-1,1])\n", "plt.title(\"Datos sint\u00e9ticos para probar el algoritmo de descenso de gradiente\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Como podemos ver, los datos generados tienen m\u00e1s de dos clases y no son linealmente separables. De lo que se infiere que el algoritmo m\u00e1s adaptado a este problema es una red neuronal con salida *softmax* y con al menos una capa oculta (o dos). <br>\n", "<br>\n", "En un primer paso, yo voy a hacer una red tipo softmax sin capas ocultas, la cual tendr\u00eda que entrenarse f\u00e1cilmente y deber\u00eda ser f\u00e1cil de visualizar si los resultados son correctos."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rn = inicializa_red_neuronal([2, 3], 'softmax')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["desc_grad(X, Y, rn, alfa=0.2, max_epochs=1000)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Y_est = f_prop(X, rn)[-1].T\n", "y_est = np.argmax(Y_est, axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Y ahora vamos a visualizar los resultados a ver si tienen sentido."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Genera un grid en todo el espacio con datos a clasificar"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["h = 0.02\n", "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n", "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n", "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n", "                     np.arange(y_min, y_max, h))\n", "X_mesh = np.c_[xx.ravel(), yy.ravel()]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Calcula la predicci\u00f3n de clase para estos datos"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Y_mesh = f_prop(X_mesh, rn)[-1].T\n", "y_mesh = np.argmax(Y_mesh, axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ajusta las salidas en forma de matriz para graficar el contorno"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_mesh = y_mesh.reshape(xx.shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure()\n", "plt.contourf(xx, yy, y_mesh, cmap=plt.cm.Spectral, alpha=0.8)\n", "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral, edgecolors='black')\n", "plt.xlim(xx.min(), xx.max())\n", "plt.ylim(yy.min(), yy.max())\n", "plt.title(\"Separaci\u00f3n lineal de los datos sint\u00e9ticos con una red neuronal sin capas ocultas\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["y si el programa funciona correctamente, el resultado deber\u00eda ser una imagen como esta:<br>\n", "<br>\n", "![Separaci\u00f3n lineal de los datos sint\u00e9ticos con una red neuronal sin capas ocultas](imagenes/espiral_linear.png)<br>\n", "<br>\n", "Si este es el caso, entonces ya estamos listos para probar el algoritmo de descenso de gradiente para una red neuronal con capas ocultas.<br>\n", "<br>\n", "**Realiza el aprendizaje con una red neuronal con capas ocultas, de forma que todos los datos sean correctamente clasificados y graf\u00edca el resultado de manera similar a como se hizo para la red neuronal sin capas ocultas.**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In[ ]:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Realiza el aprendizaje con una red neuronal con capas ocultas, <br>\n", "de forma que todos los datos sean correctamente clasificados <br>\n", "y graf\u00edca el resultado de manera similar a como se hizo para <br>\n", "la red neuronal sin capas ocultas."]}, {"cell_type": "markdown", "metadata": {}, "source": ["El resultado debe de ser una figura similar a la <br>\n", "anterior pero que se pueda ver la partici\u00f3n no lineal del espacio"]}, {"cell_type": "markdown", "metadata": {}, "source": ["-------------------------------------------<br>\n", "Insertar c\u00f3digo aqu\u00ed<br>\n", "-------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rn = inicializa_red_neuronal([2, 8, 5, 3], 'softmax')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["desc_grad(X, Y, rn, alfa=0.3, max_epochs=12000)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Y_est = f_prop(X, rn)[-1].T\n", "y_est = np.argmax(Y_est, axis=1)\n", "#---------------------------------------------\n", "# Generando un grid\n", "h = 0.02\n", "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n", "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n", "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n", "                     np.arange(y_min, y_max, h))\n", "X_mesh = np.c_[xx.ravel(), yy.ravel()]\n", "# Hace el calculo de prediccion de clase\n", "Y_mesh = f_prop(X_mesh, rn)[-1].T\n", "y_mesh = np.argmax(Y_mesh, axis=1)\n", "# Ajusta los datos en forma de matriz para el contorno\n", "y_mesh = y_mesh.reshape(xx.shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure()\n", "plt.contourf(xx, yy, y_mesh, cmap=plt.cm.Spectral, alpha=0.8)\n", "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral, edgecolors='black')\n", "plt.xlim(xx.min(), xx.max())\n", "plt.ylim(yy.min(), yy.max())\n", "plt.title(\"Separaci\u00f3n lineal de los datos sint\u00e9ticos con una red neuronal sin capas ocultas\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}